# 官网文档资料

此部分内容摘抄官方文档资料

## 内存管理指导

官网对内存子系统一共分为如下几个模块，其中有些内容已经完成，有些处于未完成阶段

- Physical Memory
- Page Tables
- Process Addresses(未完成)
- Boot Memory(未完成)
- Page Allocation(未完成)
- Virtually Contiguous Memory Allocation(未完成)
- Slab Allocation(未完成)
- High Memory Handling(几乎不用了解)
- Page Reclaim(未完成)
- Swap(未完成)
- Page Cache(未完成)
- Shared Memory Filesystem(未完成)
- Out Of Memory Handling(未完成)


## Physical Memory

Linux 可用于多种体系结构，因此需要一种**独立于体系结构**的抽象来表示物理内存。 

本章描述用于管理正在运行的系统中的物理内存的结构


内存管理中普遍存在的第一个主要概念是**非统一内存访问**`NUMA`。 

对于多核和多`sockets`机器，内存可以排列成`mem bank`，根据距处理器的`距离`，这些`bank`会产生不同的访问成本。
例如，可能有一组内存分配给每个 CPU，或者有一组非常适合外围设备附近的 DMA 的内存。

每个`mem bank`称为一个`node`，即使架构是 UMA，该概念在 Linux 下也由 struct pglist_data 表示。 
该结构始终由其 typedef pg_data_t 引用。 

特定节点的 pg_data_t 结构可以通过 `NODE_DATA(nid)` 宏引用，其中`nid` 是该节点的 ID。

对于 NUMA 架构，节点结构是在启动早期由架构特定代码分配的。

通常，这些结构在它们所代表的`bank`上本地分配。 

对于 UMA 架构，仅使用一个名为 `contig_page_data` 的静态 pg_data_t 结构。 `NODE`将在`node section`进一步讨论


整个物理地址空间被划分为一个或多个称为`ZONE`的块，它们代表内存中的**不同范围**。 
这些范围通常由访问物理内存的体系结构约束决定。 

`Node`内对应于特定`Zone`的内存范围由 `struct zone` 描述，类型定义为 `zone_t`。 每个区域都有下述类型之一。


 - `ZONE_DMA` 和 `ZONE_DMA32`:  历史上表示适合无法访问所有可寻址内存的外围设备进行 DMA 的内存。
    多年来，有更好、更强大的接口来获取具有 DMA 特定要求的内存（使用通用设备的动态DMA映射），
	但` ZONE_DMA `和 `ZONE_DMA32 `仍然表示对其访问方式有限制的内存范围。 
	根据体系结构，可以使用 `CONFIG_ZONE_DMA` 和 `CONFIG_ZONE_DMA32` 配置选项在构建时禁用这些区域类型中的任何一种，
	甚至它们都可以禁用。 某些 64 位平台可能需要两个区域，因为它们支持具有不同 DMA 寻址限制的外设。
 - `ZONE_NORMAL `: 用于内核始终可以访问的普通内存。 如果DMA设备支持传输到所有可寻址内存，
    则可以在此区域中的页面上执行 DMA操作。 `ZONE_NORMAL `始终启用。
 - `ZONE_HIGHMEM`:  是物理内存中未被内核页表中的永久映射覆盖的部分。 
    该区域中的内存只能由内核使用临时映射来访问。 该区域仅在某些 32 位体系结构上可用，并通过 `CONFIG_HIGHMEM` 启用。
 - `ZONE_MOVABLE`:  适用于普通可访问内存，就像` ZONE_NORMAL` 一样。 
    不同之处在于ZONE_MOVABLE中的大多数页面的内容是可移动的。 
	这意味着虽然这些页面的虚拟地址不会改变，但它们的内容可能会在不同的物理页面之间移动。
	通常，`ZONE_MOVABLE `在内存热插拔期间填充，但也可能在启动时使用 `kernelcore`、`movablecore` 和 `moving_node` 
	内核命令行参数之一填充。 有关更多详细信息，请参阅页面迁移和内存热插拔。
  - `ZONE_DEVICE`:  表示驻留在 `PMEM `和 `GPU` 等设备上的内存。 
     它具有与 RAM 区域类型不同的特征，它的存在是为了为设备驱动程序识别的物理地址范围提供结构页和内存映射服务。
     `ZONE_DEVICE `通过配置选项 CONFIG_ZONE_DEVICE 启用。

值得注意的是，许多内核操作只能使用 `ZONE_NORMAL` ，因此它是性能最关键的`Zone`。 `Zone`将在`Zone`章节中进一步讨论。


节点和区域范围之间的关系由固件报告的物理内存映射、内存寻址的架构约束以及内核命令行中的某些参数确定。

例如，对于具有 `2 GB `RAM 的 x86 `UMA` 计算机上的 `32 位`内核，整个内存将位于节点 0 上，
并且将存在三个区域：ZONE_DMA、ZONE_NORMAL 和 ZONE_HIGHMEM：

```
0                                                            2G
+-------------------------------------------------------------+
|                            node 0                           |
+-------------------------------------------------------------+

0         16M                    896M                        2G
+----------+-----------------------+--------------------------+
| ZONE_DMA |      ZONE_NORMAL      |       ZONE_HIGHMEM       |
+----------+-----------------------+--------------------------+
```

在ARM64机器上禁用`ZONE_DMA` 并启用`ZONE_DMA32`并使用 `movablecore = 80％`参数启动内核时，
在两个节点之间平均分配`16 GB` RAM，则节点0上将有`ZONE_DMA32`，
`ZONE_NORMAL`和`ZONE_MOVABLE`，节点1上将有`ZONE_NORMAL`和`ZONE_MOVABLE `：

```
1G                                9G                         17G
+--------------------------------+ +--------------------------+
|              node 0            | |          node 1          |
+--------------------------------+ +--------------------------+

1G       4G        4200M          9G          9320M          17G
+---------+----------+-----------+ +------------+-------------+
|  DMA32  |  NORMAL  |  MOVABLE  | |   NORMAL   |   MOVABLE   |
+---------+----------+-----------+ +------------+-------------+
```

`BANK`可以属于交错节点。 在下面的示例中，x86 机器在` 4 个BANK`中拥有 `16 GB` RAM，
偶数存储体属于节点 0，奇数存储体属于节点 1：
```
0              4G              8G             12G            16G
+-------------+ +-------------+ +-------------+ +-------------+
|    node 0   | |    node 1   | |    node 0   | |    node 1   |
+-------------+ +-------------+ +-------------+ +-------------+

0   16M      4G
+-----+-------+ +-------------+ +-------------+ +-------------+
| DMA | DMA32 | |    NORMAL   | |    NORMAL   | |    NORMAL   |
+-----+-------+ +-------------+ +-------------+ +-------------+
```

在这种情况下，`NODE0` 的跨度为 0 到 12 GB，`NODE1` 的跨度为 4 到 16 GB。

### Nodes

正如我们所提到的，内存中的每个节点都由 `pg_data_t` 描述，它是 `struct pglist_data `的 `typedef`。 
分配页面时，默认情况下Linux使用节点本地分配策略从最接近正在运行的CPU的节点分配内存。 

由于进程往往在同一 CPU 上运行，因此很可能会使用当前节点的内存。 分配策略可以由用户控制，如 NUMA 内存策略中所述。

大多数 NUMA 架构都维护一个指向`node`的指针数组。 
当架构特定的代码解析固件报告的物理内存映射时，实际的结构在引导期间尽早分配。 

大部分节点初始化稍后在引导过程中通过 `free_area_init() `函数进行，稍后将在初始化部分中进行描述。

除了`struct node`之外，内核还维护一个名为 `node_states` 的` nodemask_t` 位掩码数组。 
该数组中的每个位掩码代表一组具有枚举 `node_states` 定义的特定属性的节点：

 - N_POSSIBLE : The node could become online at some point.

 - N_ONLINE ：The node is online.

 - N_NORMAL_MEMORY : The node has regular memory.

 - N_HIGH_MEMORY : The node has regular or high memory. When CONFIG_HIGHMEM is disabled aliased to N_NORMAL_MEMORY.

 - N_MEMORY: The node has memory(regular, high, movable)

 - N_CPU :The node has one or more CPUs
 
对于具有上述属性的每个节点，设置与 `node_states[<property>]` 位掩码中的节点 ID 相对应的位。

例如，对于具有正常内存和 CPU 的`Node 2`，`bit 2` 将被设置为
```
node_states[N_POSSIBLE]
node_states[N_ONLINE]
node_states[N_NORMAL_MEMORY]
node_states[N_HIGH_MEMORY]
node_states[N_MEMORY]
node_states[N_CPU]
```

有关使用节点掩码可能进行的各种操作，请参阅 `include/linux/nodemask.h`

其中，节点掩码用于提供节点遍历的宏，即 `for_each_node()` 和 `for_each_online_node()`

例如，为每个在线节点调用函数 foo()：
```
for_each_online_node(nid) {
        pg_data_t *pgdat = NODE_DATA(nid);

        foo(pgdat);
}
```

### Node 结构

节点结构` struct pglist_data` 在` include/linux/mmzone.h `中声明。 这里我们简单描述一下这个结构体的字段：

#### 通用字段

  - `node_zones`: 该`NODE` 包含的`Zone`。 并非所有`Zone`都已填充，但这是完整列表。 
    它被该节点的`node_zonelists`以及其他节点的`node_zonelists`引用
  - `node_zonelists`: 所有`Node`的所有`zONE`的列表。 此列表定义了优先分配的`Zone`的顺序。 
    ` node_zonelists`是在核心内存管理结构初始化期间由 `mm/page_alloc.c` 中的 `build_zonelists()` 设置的。
  - `nr_zones`: 该节点中已填充`zONE`的数量。
  - `node_mem_map`:对于使用 `FLATMEM` 内存模型的 `UMA `系统，0 的节点` node_mem_map` 是表示每个物理帧的结构页数组
  - `node_start_pfn`: 该节点中起始页框的页框号。
  - `node_present_pages`: 该节点中存在的物理页总数。
  - `node_spanned_pages`:物理页范围的总大小，包括空洞
  - `node_size_lock`:物理页范围的总大小，保护定义节点范围的字段的锁。 
     仅当至少启用` CONFIG_MEMORY_HOTPLUG` 或` CONFIG_DEFERRED_STRUCT_PAGE_INIT `配置选项之一时才定义。
	 提供 `pgdat_resize_lock()` 和` pgdat_resize_unlock() `来操作` node_size_lock`，
	 而不检查 `CONFIG_MEMORY_HOTPLUG` 或 `CONFIG_DEFERRED_STRUCT_PAGE_INIT`
  - `node_id`
  - `totalreserve_pages`:这是每个节点保留的页面，不可用于用户空间分配。
  - `first_deferred_pfn`：如果大型机器上的内存初始化被推迟，那么这是第一个需要初始化的 PFN。 
     仅当 `CONFIG_DEFERRED_STRUCT_PAGE_INIT `启用时定义
  - `deferred_split_queue`:每个节点的大页面队列，其分割被推迟。 仅当启用 `CONFIG_TRANSPARENT_HUGEPAGE` 时定义。
  - `__lruvec`： 每个节点 `lruvec `保存 LRU 列表和相关参数。 仅在禁用内存 cgroup 时使用。 
    不应直接访问它，而是使用 `mem_cgroup_lruvec() `来查找 `lruvecs`。

#### 内存回收字段

未完成 只列出了node中的一些字段

 - `kswapd`:每个`node`有一个内存回收内核线程
 - `kswapd_wait, pfmemalloc_wait, reclaim_wait`: 用于同步内存回收任务的工作队列
 - `nr_writeback_throttled`:因等待脏页清理而受到限制的任务数。
 - `nr_reclaim_start`: 指标代表在回收被限制等待回写时写入的页面数量。
 - `kswapd_order`: 控制 kswapd 尝试回收的顺序
 - `kswapd_highest_zoneidx`: kswapd要回收的最高区域索引
 - `kswapd_failures`:kswapd 无法回收任何页面的运行次数
 - `min_unmapped_pages`: 无法回收的未映射文件支持页面的最小数量。 由 `vm.min_unmapped_ratio sysctl` 确定。
     仅在启用 `CONFIG_NUMA `时定义。
 - `min_slab_pages`:无法回收的 SLAB 页的最小数量。 由` vm.min_slab_ratio sysctl `确定。 仅在启用` CONFIG_NUMA `时定义
 - `flags`:控制内存回收标记
 
#### 压缩控制字段

 - `kcompactd_max_order` :kcompactd 应该尝试实现的页面大小。
 - `kcompactd_highest_zoneidx` : kcompactd 要压缩的最高区域索引。
 - `kcompactd_wait`:Workqueue 用于同步内存压缩任务。
 - `kcompactd`:每个`node`有一个内存压缩线程
 - `proactive_compact_trigger`:确定是否启用主动压缩。 由 `vm.compaction_proactiveness sysctl` 控制。

#### 统计

 - `per_cpu_nodestats`: 节点的每 CPU VM 统计信息
 - `vm_stat`: 每个节点的虚拟内存统计
 

## PageTables

分页虚拟内存与虚拟内存这一概念一起于 1962 年在 Ferranti Atlas 计算机上发明，这是第一台具有分页虚拟内存的计算机。 
随着时间的推移，该功能迁移到较新的计算机上，并成为所有类 Unix 系统事实上的功能。 
1985 年，该功能被包含在 Intel 80386 中，Linux 1.0 就是在该 CPU 上开发的。

页表将 CPU 看到的虚拟地址映射到外部内存总线上看到的物理地址。


Linux 将页表定义为一个层次结构，目前的高度为五级。 然后，每个受支持架构的架构代码会将其映射到硬件的限制。

虚拟地址对应的物理地址常常被底层物理页框引用。 
页框号或 pfn 是页的物理地址（如在外部存储器总线上看到的）除以 PAGE_SIZE。

物理内存地址0将是pfn 0，最高的pfn将是CPU外部地址总线可以寻址的物理内存的最后一页。

页粒度为 4KB，地址范围为 32 位，`pfn 0` 位于地址 `0x00000000`，`pfn 1 `位于地址 `0x00001000`，
`pfn 2` 位于` 0x00002000`，依此类推，直到到达 `0xfffff000 `处的 `pfn 0xfffff`。 

对于 16KB 页面，pfs 位于 `0x00004000`、`0x00008000 ... 0xffffc000`，`pfn `从 `0` 到 `0x3fffff`。

正如您所看到的，对于 4KB 页面，页面基地址使用地址的第 `12-31` 位，这就是为什么在这种情况下 
`PAGE_SHIFT `定义为 12，而 `PAGE_SIZE` 通常根据页面移位定义为 (1 << PAGE_SHIFT ）


随着时间的推移，为了响应不断增加的内存大小，已经开发出更深的层次结构。 
当 Linux 创建时，使用了 4KB 页面和一个名为 `swapper_pg_dir` 的包含` 1024` 个条目的页表，
覆盖 `4MB`，这与 Torvald 的第一台计算机拥有 4MB 物理内存的事实相吻合。 该表中的条目称为 PTE:s - 页表条目。

软件页表层次结构反映了页表硬件已经分层的事实，这反过来又是为了节省页表内存并加快映射速度。

人们当然可以想象一个包含大量条目的单个线性页表，将整个内存分解为单个页面。

 这样的页表将非常稀疏，因为大部分虚拟内存通常保持未使用状态。 
 
 通过使用分层页表，虚拟地址空间中的大洞不会浪费宝贵的页表内存，
 因为它足以在页表层次结构中的较高级别将大区域标记为未映射。
 
 此外，在现代 CPU 上，更高级别的页表条目可以直接指向物理内存范围，
 这允许在单个高级页表条目中映射几兆字节甚至千兆字节的连续范围，从而将虚拟内存映射到 物理内存：
 当您找到这样的大映射范围时，无需在层次结构中进行更深入的遍历。
 
 
页表层次结构现在已经发展成这样：

```
+-----+
| PGD |
+-----+
   |
   |   +-----+
   +-->| P4D |
       +-----+
          |
          |   +-----+
          +-->| PUD |
              +-----+
                 |
                 |   +-----+
                 +-->| PMD |
                     +-----+
                        |
                        |   +-----+
                        +-->| PTE |
                            +-----+
```

页表层次结构的不同级别上的符号从底部开始具有以下含义：

 - `pte, pte_t, pteval_t` = 页表条目; 前面提到过。` pte` 是` pteval_t` 类型的 `PTRS_PER_PTE` 元素的数组，
    每个元素将虚拟内存的单页映射到物理内存的单页。 该架构定义了 `pteval_t `的大小和内容。
    一个典型的例子是 pteval_t 是一个 32 位或 64 位值，其中高位是 `pfn`，低位是一些特定于体系结构的位，例如内存保护。

重复一下：页表层次结构中的每个级别都是一个指针数组，因此` pgd `包含指向下一个级别的 
`PTRS_PER_PGD` 指针，`p4d` 包含指向 `pud `项的 `PTRS_PER_P4D `指针，依此类推。 
每个级别上的指针数量是体系结构定义的：

```
      PMD
--> +-----+           PTE
    | ptr |-------> +-----+
    | ptr |-        | ptr |-------> PAGE
    | ptr | \       | ptr |
    | ptr |  \        ...
    | ... |   \
    | ptr |    \         PTE
    +-----+     +----> +-----+
                       | ptr |-------> PAGE
                       | ptr |
                         ...
```

### 页表折叠 

如果体系结构不使用所有页表级别，则可以折叠它们，这意味着跳过，
并且对页表执行的所有操作都将在编译时增强，以便在访问下一个较低级别时跳过一个级别。
​
需要编写希望与体系结构无关的页表处理代码（例如虚拟内存管理器），
以便它遍历当前的所有五个级别。 这种风格也应该是特定于体系结构的代码的首选，以便对未来的变化具有鲁棒性。

### MMU TLB 和 page fault
内存管理单元 (MMU) 是处理虚拟地址到物理地址转换的硬件组件。 它可以在硬件中使用相对较小的高速缓存，
称为转换后备缓冲区 (TLB) 和页面遍历高速缓存来加速这些转换。 

当 CPU 访问内存位置时，它会向 `MMU `提供虚拟地址，`MMU` 检查 `TLB` 或 `Page Walk Cache` 中是否存在现有转换
（在支持它们的体系结构上）。 如果没有找到，`MMU` 使用页面遍历来确定物理地址,并创建映射。

当页面被写入时，页面的脏位被设置（即，打开）。 
每个内存页都有关联的权限和脏位。 后者表明该页面自加载到内存以来已被修改。

如果没有任何阻碍，最终可以访问物理内存并在物理帧上执行请求的操作。


MMU 找不到映射的原因有多种。 发生这种情况的原因可能是 CPU 正在尝试访问当前任务不允许的内存，
或者数据未存在于物理内存中。

当这些情况发生时，MMU 会触发页面错误，这是一种异常类型，通知 CPU 暂停当前执行并运行特殊函数来处理提到的异常。

页面错误有一些常见的和预期的原因。 这些是由称为`延迟分配`和`写入时复制`的进程管理优化技术触发的。 
当帧被换出到持久存储（交换分区或文件）并从其物理位置逐出时，也可能会发生页面错误。

这些技术提高了内存效率，减少了延迟，并最大限度地减少了空间占用。 
本文档不会更深入地讨论“延迟分配”和“写入时复制”的细节，因为这些主题超出了范围，因为它们属于进程地址管理。


交换与其他提到的技术不同，因为它是不可取的，因为它是作为在高压力下减少内存的一种手段来执行的。

交换不能用于内核逻辑地址映射的内存。 它们是内核虚拟空间的子集，直接映射连续的物理内存范围。

给定任何逻辑地址，其物理地址是通过偏移量的简单算术确定的。对逻辑地址的访问速度很快，
因为它们避免了复杂的页表查找，但代价是帧不可逐出和可分页。

如果内核无法为物理帧中必须存在的数据腾出空间，内核会调用内存不足 (OOM) 杀手，
通过终止较低优先级进程来腾出空间，直到压力降低到安全阈值以下。


此外，页面错误也可能是由代码错误或 CPU 被指示访问的恶意制作的地址引起的。 进程的线程可以使用指令来寻址不属于其自己的地址空间的（非共享）内存，
或者可以尝试执行想要写入只读位置的指令。

如果上述情况发生在用户空间，内核将向当前线程发送分段错误（SIGSEGV）信号。 该信号通常会导致线程及其所属进程的终止。

本文档将简化并展示 Linux 内核如何处理这些页面错误、创建表和表条目、检查内存是否存在以及如果不存在则请求从持久存储或其他设备加载数据的高空视图 ，
并更新 MMU 及其缓存。


第一步取决于架构。 大多数体系结构跳转到 `do_page_fault()`，而 x86 中断处理程序由调用
` handle_page_fault() `的 `DEFINE_IDTENTRY_RAW_ERRORCODE()` 宏定义。

无论采用何种路线，所有体系结构最终都会调用`handle_mm_fault()`，
而`handle_mm_fault()`（很可能）最终会调用`__handle_mm_fault()`来执行分配页表的实际工作。

不幸的是，无法调用 `__handle_mm_fault() `意味着虚拟地址指向不允许访问的物理内存区域（至少从当前上下文）。
 这种情况导致内核向进程发送上述 SIGSEGV 信号，并导致已经解释过的后果。
 
`__handle_mm_fault()` 通过调用几个函数来查找页表上层条目的偏移量并分配它可能需要的表来完成其工作。

查找偏移量的函数的名称类似于 `*_offset()`， `pgd、p4d、pud、pmd、pte`； 
相反，逐层分配相应表的函数称为`*_alloc`，使用上述约定以层次结构中相应类型的表来命名它们。

页表遍历可能在中层或上层（PMD、PUD）之一结束。

Linux 支持比通常的 4KB 更大的页面大小（即所谓的大页面）。 
当使用这些较大的页面时，较高级别的页面可以直接映射它们，
而不需要使用较低级别的页面条目（PTE）。 

大页面包含通常从 2MB 到 1GB 的大型连续物理区域。 它们分别由`PMD`和`PUD`页条目映射。

大页面带来了多种好处，例如减少 TLB 压力、减少页表开销、内存分配效率以及某些工作负载的性能改进。 
然而，这些好处也伴随着权衡，例如内存浪费和分配挑战。

在分配过程的最后，如果没有返回错误，`__handle_mm_fault()` 最终调用`handle_pte_fault()`，
后者通过 `do_fault() `执行 `do_read_fault()`、`do_cow_fault()`、`do_shared_fault()` 之一。 
“read”、“cow”、“shared”给出了有关其处理的故障原因和类型的提示。

工作流程的实际实现非常复杂。 
其设计允许 Linux 以针对每种体系结构的特定特征定制的方式处理页面错误，同时仍然共享通用的整体结构。

为了总结 Linux 如何处理页面错误的高空视图，让我们补充一下，可以使用 `pagefault_disable()` 和 `pagefault_enable() `
分别禁用和启用页面错误处理程序。

多个代码路径使用后两个函数，因为它们需要禁用页面错误处理程序中的陷阱，主要是为了防止死锁。



## 内存管理员文档

顾名思义，Linux 内存管理子系统负责管理系统中的内存。这包括实现虚拟内存和需求分页、
为内核内部结构和用户空间程序分配内存、将文件映射到进程地址空间以及许多其他很酷的事情。

Linux 内存管理是一个复杂的系统，有许多可配置的设置。
这些设置大多可通过 `/proc` 文件系统获取，并可使用 sysctl 进行查询和调整。
这些 API 在` /proc/sys/vm/ `文档和` man 5 proc `中都有描述。

在此，我们将详细介绍如何与 Linux 内存管理中的各种机制进行交互。

### 概念概述

Linux 中的内存管理是一个复杂的系统，经过多年的发展，包含了越来越多的功能，
以支持从无 MMU 微控制器到超级计算机的各种系统。针对无 MMU 系统的内存管理被称为 nommu，
它绝对值得专门编写一份文档，希望最终能写成。不过，虽然某些概念是相同的，但这里我们假设有 MMU，
CPU 可以将虚拟地址转换为物理地址。

#### 虚拟内存入门

计算机系统中的物理内存是有限的资源，即使是支持内存热插拔的系统，可安装的内存量也有硬性限制。
物理内存并不一定是连续的，它可以作为一组不同的地址范围来访问。
此外，不同的 CPU 架构，甚至同一架构的不同实现方式，对如何定义这些地址范围也有不同的看法。

为了避免这种复杂性，我们提出了虚拟内存的概念。

虚拟内存从应用软件中抽象出了物理内存的细节，允许在物理内存中只保留所需的信息（需求分页），
并提供了一种在进程间保护和有控制地共享数据的机制。

使用虚拟内存时，每次内存访问都使用一个虚拟地址。当中央处理器解码从系统内存读取（或写入）的指令时，
它会将指令中编码的虚拟地址转换为内存控制器可以理解的物理地址。

物理系统内存被划分为页面框架或页面。每个页面的大小取决于具体的架构。某些架构允许从多个支持值中选择页面大小；
这种选择在内核构建时通过设置适当的内核配置选项来完成。

每个物理内存页面都可以映射为一个或多个虚拟页面。这些映射由页表描述，
页表允许将程序使用的虚拟地址转换为物理内存地址。页表按层次组织。

层次结构最底层的表包含软件实际使用页面的物理地址。较高层次的表包含属于较低层次的页面的物理地址。
顶层页表的指针位于寄存器中。CPU 执行地址转换时，使用该寄存器访问顶层页表。
虚拟地址的高位用于索引顶层页表中的一个条目。然后使用该条目访问层次结构中的下一级，
并将虚拟地址的下一位作为该级页表的索引。虚拟地址的最低位定义实际页面内的偏移量。

#### 大页 

地址转换需要多次访问内存，而访问内存的速度相对于 CPU 的速度较慢。为避免将宝贵的处理器周期耗费在地址转换上，
CPU 会将此类转换保存在一个缓存中，该缓存称为转换旁侧缓存（或 TLB）。
通常，TLB 是非常稀缺的资源，具有大型内存工作集的应用程序会因为 TLB 未命中而受到性能影响。


许多现代 CPU 架构允许直接通过页表中的较高层次映射内存页。例如，在 x86 处理器上，可以使用二级和三级页表中的条目映射 
2M 甚至 1G 的页面。在 Linux 中，这种页面被称为超大页面。使用超大页可以大大减轻 TLB 的压力，
提高 TLB 命中率，从而提高系统的整体性能。

Linux 中有两种机制可以实现物理内存与超大页的映射。第一种是 `HugeTLB `文件系统，或` hugetlbfs`。
这是一种使用 `RAM `作为后备存储的`伪文件系统`。对于在该文件系统中创建的文件，数据驻留在内存中，
并使用巨页进行映射。有关 hugetlbfs 的介绍，请访问 [HugeTLB Pages](https://www.kernel.org/doc/html/latest/admin-guide/mm/hugetlbpage.html)


另一种较新的巨量页使用机制被称为透明巨量页（`Transparent HugePages`）或 `THP`。
hugetlbfs 要求用户和/或系统管理员配置系统内存的哪些部分应该或可以被巨量页映射，
而 THP 则不同，它以对用户透明的方式管理这些映射，因此得名。有关 THP 的更多详情，请参阅
[Transparent Hugepage Support](https://www.kernel.org/doc/html/latest/admin-guide/mm/transhuge.html)


#### ZONES
 
硬件通常会对如何访问不同的物理内存范围做出限制。在某些情况下，设备无法对所有可寻址内存执行 DMA。
在其他情况下，物理内存的大小超过了虚拟内存的最大可寻址大小，需要采取特殊措施才能访问部分内存。
Linux 会根据内存页的可能用途将其划分为不同的区域。例如，ZONE_DMA 包含可被设备用于 DMA 的内存，
ZONE_HIGHMEM 包含未永久映射到内核地址空间的内存，而 ZONE_NORMAL 则包含正常寻址的内存页。

内存区的实际布局取决于硬件，因为并非所有架构都定义了所有内存区，而且不同平台对 DMA 的要求也不同。

#### Nodes

许多多处理器机器都是 NUMA（非统一内存访问）系统。在这种系统中，内存被排列成不同的内存组，
根据与处理器的 "距离 "不同，访问延迟也不同。每个内存库被称为一个节点，
Linux 为每个节点构建了一个独立的内存管理子系统。每个节点都有自己的区域、
可用和已用页面列表以及各种统计计数器。有关 NUMA 的更多详情，请参阅《什么是 NUMA》和《NUMA 内存策略》。

#### Page Cache
物理内存是易失性的，将数据读入内存的常见情况是从文件中读取数据。每当读取文件时，数据都会被放入页面缓存，
以避免后续读取时昂贵的磁盘访问。同样，在向文件写入数据时，数据也会被放入页面缓存，
并最终进入后备存储设备。写入的页面会被标记为 "脏"，当 Linux 决定将它们用于其他用途时，
就会确保设备上的文件内容与更新的数据同步。


#### Anonymous Memory
匿名内存或匿名映射代表没有文件系统支持的内存。此类映射是为程序的堆栈和堆隐式创建的，
或者是通过显式调用 `mmap(2)` 系统调用创建的。通常，匿名映射只定义允许程序访问的虚拟内存区域。
读取访问将导致创建一个页表项，该页表项将引用一个填满 `0 `的特殊物理页。当程序执行写操作时，
将分配一个常规物理页来保存写入的数据。该页将被标记为`脏页`，如果内核决定重新使用该页，脏页将被交换出去。

#### 回收

在整个系统生命周期中，物理页可用于存储不同类型的数据。它可以是内核内部数据结构、
供设备驱动程序使用的 DMA 缓冲区、从文件系统读取的数据、用户空间进程分配的内存等。

根据页面的使用情况，Linux 内存管理会对其进行不同的处理。可以随时释放的页面被称为可回收页面（reclaimable），
这是因为这些页面缓存了其他地方的数据，比如硬盘上的数据，或者因为这些页面可以被交换出去，
比如交换到硬盘上。可回收页面中最显著的类别是`页面缓存`和`匿名内存`。

在大多数情况下，保存内部内核数据和用作 DMA 缓冲区的页面不能被重新利用，它们会一直被钉住，
直到用户释放为止。这种页面被称为不可回收页面。不过，在某些情况下，即使是内核数据结构占用的页面也可以被回收。
例如，文件系统元数据的内存缓存可以从存储设备中重新读取，因此当系统受到内存压力时，可以从主存中释放这些缓存。

释放可回收的物理内存页并重新利用它们的过程称为回收。Linux 可以异步或同步回收内存页，
具体取决于系统的状态。系统未加载时，大部分内存都是空闲的，分配请求会立即从空闲页面中得到满足。
随着负载的增加，空闲页的数量会逐渐减少，当达到某个阈值（低水印）时，
分配请求就会唤醒 `kswapd `守护进程。它将异步扫描内存页，如果其中的数据在其他地方可用，
则释放这些页，或者将其驱逐到后备存储设备（还记得那些脏页吗？）当内存使用量进一步增加并达到另一个阈值（最小水印）时，
分配将触发直接回收。在这种情况下，分配会停止，直到有足够的内存页被回收以满足请求。

#### 压缩

随着系统的运行，任务会分配和释放内存，内存就会变得支离破碎。虽然虚拟内存可以将分散的物理页显示为虚拟毗连的范围，
但有时需要分配大的物理毗连内存区域。例如，当设备驱动程序需要大缓冲区用于 DMA 或 THP 分配大页面时，
就会出现这种需要。内存压缩可解决碎片问题。这种机制会将内存区域下部的占用页面移动到区域上部的空闲页面。
当压缩扫描结束后，空闲页面会被集中到区域的起始位置，这样就可以分配大的物理连续区域了。

与回收一样，压缩可能在 kcompactd 守护进程中异步发生，也可能由于内存分配请求而同步发生。


#### OOM killer

在已加载的机器上，内存有可能会耗尽，内核将无法回收足够的内存来继续运行。为了挽救系统的其他部分，内核会调用 `OOM killer`

OOM 杀手会选择一个任务来牺牲,换取整个系统的健康状况。 
选定的任务被终止，希望在它退出后能够释放足够的内存以继续正常操作。
